{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Evaluate_TFLite_sidewalk_model.ipynb","provenance":[{"file_id":"1DZrTj3LFe9L1b_aIEuu60ODfDnS5ov6w","timestamp":1586459159170},{"file_id":"1xCMNiRq9fqMG4zQUNU6HZFqAH2GXwA_5","timestamp":1581436745155},{"file_id":"1OhgTI1t98xVDgmwUWOVD7wOwgyRYkmaT","timestamp":1571342698340},{"file_id":"https://github.com/tensorflow/examples/blob/master/community/en/flowers_tf_lite.ipynb","timestamp":1567890810927}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hLwfwSmLeyWF"},"source":["# Evaluate TF-lite model to recognize sidewalks. \n","\n"]},{"cell_type":"code","metadata":{"id":"giC8DpjMmxuZ","colab_type":"code","colab":{}},"source":["!pip install tensorflow-gpu==2.0.0\n","!pip install tensorflow_hub\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import matplotlib.pylab as plt\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AfXsUSrlaqxB","colab_type":"text"},"source":["### Initialize and load model"]},{"cell_type":"code","metadata":{"id":"BtgaTtZ-D8Sw","colab_type":"code","outputId":"68df077d-a253-4c9f-fd51-e41acb196e7d","executionInfo":{"status":"ok","timestamp":1587169214509,"user_tz":360,"elapsed":8080,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}},"colab":{"base_uri":"https://localhost:8080/","height":68}},"source":["# Set location of test data and saved models on google drive\n","#data_path = \"LA_test1_rev2\"\n","data_path = \"LA_train2\"\n","#data_path = \"040120\"\n","#image_dir = 'drive/My Drive/CoLab_Data/Hollywood/'\n","image_dir = 'drive/My Drive/CoLab_Data/LosAngeles/'\n","saved_model_dir = 'drive/My Drive/CoLab_Data/save/'\n","\n","\n","# import dependencies\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%tensorflow_version 2.x\n","import tensorflow as tf\n","from google.colab import files\n","from google.colab import drive\n","from sklearn.metrics import classification_report, confusion_matrix\n","\n","# connect to Google drive\n","drive.mount('/content/drive')\n","\n","# unzip training images to local colab drive\n","unzip_path = '%s%s.zip' % (image_dir, data_path)\n","print(unzip_path)\n","os.system('unzip \"%s%s.zip\"' % (image_dir, data_path))\n","#os.system('rm %s/*.txt' % data_path)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","drive/My Drive/CoLab_Data/LosAngeles/LA_train2.zip\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["256"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"urbEpkQhiFMz","colab_type":"code","colab":{}},"source":["# Load tflite model directly \n","model_name = 'mobileV2_LA_0407'\n","#model = tf.keras.models.load_model(saved_model_dir + model_name + '.tflite')\n","tflite_interpreter = tf.lite.Interpreter(model_path=saved_model_dir + model_name + '.tflite')\n","\n","input_details = tflite_interpreter.get_input_details()\n","output_details = tflite_interpreter.get_output_details()\n","\n","print(\"== Input details ==\")\n","print(\"name:\", input_details[0]['name'])\n","print(\"shape:\", input_details[0]['shape'])\n","print(\"type:\", input_details[0]['dtype'])\n","\n","print(\"\\n== Output details ==\")\n","print(\"name:\", output_details[0]['name'])\n","print(\"shape:\", output_details[0]['shape'])\n","print(\"type:\", output_details[0]['dtype'])\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YtHcok4Lh4Xi","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"de2562b2-607a-4bf2-f630-53045d73953c","executionInfo":{"status":"ok","timestamp":1587169237618,"user_tz":360,"elapsed":16125,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}}},"source":["# or load float model\n","\n","# Load float model  \n","model_name = 'mobileV2_LA_0407'\n","model = tf.keras.models.load_model(saved_model_dir + model_name + '.h5')\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YdGzgC7CpyIO","colab_type":"code","colab":{}},"source":["# optionally load weights from checkpoint\n","checkpoint = 'cp-0015.ckpt'\n","checkpoint_path = 'drive/My Drive/CoLab_Data/save/mobileV2_LA_0407'\n","model.load_weights(checkpoint_path + '/' + checkpoint)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JXJ0Q0knWc8b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"outputId":"3870d748-62f7-47ef-8e48-b7b012203f1d","executionInfo":{"status":"ok","timestamp":1587169273599,"user_tz":360,"elapsed":27873,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}}},"source":["# Convert from float model to tflite model\n","\n","TFLITE_MODEL = 'mobileV2_LA_0407a.tflite'\n","\n","# Load float model  \n","model_name = 'mobileV2_LA_0407'\n","model = tf.keras.models.load_model(saved_model_dir + model_name + '.h5')\n","\n","\n","####### Convert for 2.0 using concrete functions #####\n","# Get the concrete function from the Keras model.\n","run_model = tf.function(lambda x : model(x))\n","\n","# Save the concrete function.\n","concrete_func = run_model.get_concrete_function(\n","    tf.TensorSpec(model.inputs[0].shape, model.inputs[0].dtype)\n",")\n","\n","# Convert the model\n","converter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\n","tflite_model = converter.convert()\n","open(TFLITE_MODEL, \"wb\").write(tflite_model)\n","\n","# load Tflite model\n","tflite_interpreter = tf.lite.Interpreter(model_path=TFLITE_MODEL)\n","input_details = tflite_interpreter.get_input_details()\n","output_details = tflite_interpreter.get_output_details()\n","\n"],"execution_count":3,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1SPuPQrfZyXU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"05efb503-4ee6-41a8-fe83-c99b5ff1f784","executionInfo":{"status":"ok","timestamp":1587169278507,"user_tz":360,"elapsed":795,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}}},"source":["\n","os.system('rm -r %s/val/side' % data_path)\n","os.system('rm -r %s/val/bike_lane' % data_path)\n","os.system('rm -r %s/val/street' % data_path)\n","tf.__version__"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'2.0.0'"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"96dwta04Shfz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":514},"outputId":"2adbb1f5-0101-4a16-89ea-d4d5dcc69f5a","executionInfo":{"status":"error","timestamp":1587169290172,"user_tz":360,"elapsed":9344,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}}},"source":["# run inference on images\n","\n","\n","# define image size and classes\n","IMAGE_SIZE = 224\n","IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n","CLASS_NAMES=('bike_lane', 'crosswalk', 'side','street')\n","\n","BATCH_SIZE = 100\n","\n","#eval_folder = \"train\"\n","eval_folder = \"val\"\n","data_path_eval = data_path + '/' + eval_folder\n","print(data_path_eval)\n","\n","# open file for inference results\n","outFile = image_dir + data_path + eval_folder + '_out_data.txt'\n","outf = {'frame' : 0, 'label' : 1, 'class' : 2, 'swFlag' : 8, 'pos' : 9, 'vel' : 12}\n","outfile_format = '%5s,%d,' + 6 * '%3.2f,' + '%d,' + 3 * '%14.9f,' + 3 * '%5.2f,' + '\\n'\n","#fid = open(outFile, \"w\")\n","\n","# create image generator\n","datagen_val = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n","gen = datagen_val.flow_from_directory(\n","    data_path_eval,\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle = False)\n","num_images = gen.n\n","\n","# allocate tensors\n","tflite_interpreter.resize_tensor_input(input_details[0]['index'], (BATCH_SIZE, 224, 224, 3))\n","tflite_interpreter.resize_tensor_input(output_details[0]['index'], (BATCH_SIZE, 4))\n","tflite_interpreter.allocate_tensors()\n","\n","# run inference on images and write results to file\n","ix=0\n","lb = []\n","y_pred = []\n","for n in range(num_images // BATCH_SIZE + 1):\n","  print(n * BATCH_SIZE)\n","  image_batch, label_batch = next(gen)\n","  label_batch = np.argmax(label_batch, axis=1)\n","\n","  #Y_pred = model.predict(image_batch)\n","  #y_pred=np.concatenate((y_pred,np.argmax(Y_pred, axis=1)))\n","  #lb=np.concatenate((lb, label_batch))\n","\n","  tflite_interpreter.set_tensor(input_details[0]['index'], image_batch)\n","  tflite_interpreter.invoke()\n","  tflite_model_predictions = tflite_interpreter.get_tensor(output_details[0]['index'])\n","  print(\"Prediction results shape:\", tflite_model_predictions.shape)\n","\n","  #for n in range(len(label_batch)):\n","  #  fn = gen.filenames[n+ix]\n","  #  img_num = fn[-19:-13] + fn[-12:-10] + fn[-9:-4]\n","  #  fid.write(outfile_format % (img_num, y_pred[ix+n], Y_pred[n][0], Y_pred[n][1],\n","  #            Y_pred[n][2], Y_pred[n][3], 0, 0, 0, 0, 0, 0, 0, 0, 0))\n","  #ix += BATCH_SIZE\n","\n","#fid.close()\n","\n","# create Confusion Matrix\n","print('Confusion Matrix')\n","cm = confusion_matrix(lb, y_pred)\n","cm_norm = np.around(cm.astype('float') / cm.sum(axis=1)[:, np.newaxis], decimals=3)\n","print(cm_norm)\n","\n","# Calculate summary numbers for side and street\n","#print('False positive: %5.1f%%' % (100 * cm_norm[0,1]))\n","#print('False negative: %5.1f%%' % (100 * cm_norm[1,0]))\n","\n","# Calculate summary numbers for side, street, and crosswalk\n","print('False positive: %5.2f%%' % (100 * (cm[0,1] + cm[0,2] + cm[3,1] + cm[3,2]) / np.sum(cm)))\n","print('False negative: %5.2f%%' % (100 * (cm[1,0] + cm[1,3] + cm[2,0] + cm[2,3]) / np.sum(cm)))\n","\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["LA_train2/val\n","Found 441 images belonging to 2 classes.\n","0\n","Prediction results shape: (100, 4)\n","100\n","Prediction results shape: (100, 4)\n","200\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-84ce6f7fa37b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0mtflite_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m   \u001b[0mtflite_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m   \u001b[0mtflite_model_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtflite_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'index'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction results shape:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtflite_model_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \"\"\"\n\u001b[1;32m    452\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_safe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interpreter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreset_all_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\u001b[0m in \u001b[0;36mInvoke\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mInvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_tensorflow_wrap_interpreter_wrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreterWrapper_Invoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mInputIndices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"TbjnXYWLU0l3","colab_type":"code","outputId":"55c72cc9-cb9d-422b-ddaa-ff148a8335e1","executionInfo":{"status":"ok","timestamp":1587169293724,"user_tz":360,"elapsed":334,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["print(tflite_model_predictions[0:100,:\n","                               ])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[[6.61599353e-09 9.99968171e-01 4.31540457e-06 2.75521743e-05]\n"," [1.20515153e-06 9.91672099e-01 6.03592616e-06 8.32069758e-03]\n"," [1.27343299e-07 9.99576509e-01 3.56583296e-05 3.87718901e-04]\n"," [1.10948224e-06 9.97642815e-01 9.37783261e-05 2.26219464e-03]\n"," [1.37709762e-07 9.99139309e-01 6.22028951e-04 2.38610941e-04]\n"," [3.98477606e-09 9.99049962e-01 7.41084281e-04 2.08870217e-04]\n"," [7.32235276e-06 9.99875426e-01 6.28895975e-08 1.17118994e-04]\n"," [5.49942815e-05 9.99683976e-01 3.85968946e-07 2.60726782e-04]\n"," [1.82137010e-04 9.97379720e-01 1.71448082e-05 2.42093555e-03]\n"," [8.99236625e-07 9.99032378e-01 1.43438901e-05 9.52394970e-04]\n"," [7.90224632e-08 9.99993443e-01 1.40654507e-07 6.29709712e-06]\n"," [7.99858981e-07 9.99883056e-01 5.70705254e-07 1.15444724e-04]\n"," [2.58742748e-05 9.85231161e-01 3.43310559e-04 1.43997138e-02]\n"," [3.51282154e-07 9.98625875e-01 2.92303866e-05 1.34451897e-03]\n"," [1.02757243e-08 9.99996781e-01 1.15406380e-07 3.07558321e-06]\n"," [3.13575384e-07 9.99841094e-01 5.79053849e-05 1.00603313e-04]\n"," [1.98368923e-07 9.99922395e-01 6.60468431e-05 1.13590968e-05]\n"," [3.66699624e-06 9.98669982e-01 2.82938243e-04 1.04339456e-03]\n"," [2.83551849e-10 9.99999285e-01 1.09748683e-07 6.23426388e-07]\n"," [1.54661484e-09 9.99999881e-01 2.02627142e-08 1.02919628e-07]\n"," [1.57752977e-09 9.99998927e-01 3.22005803e-07 7.19507909e-07]\n"," [2.39568891e-07 9.99982834e-01 1.68465192e-07 1.68510687e-05]\n"," [2.15640283e-09 9.99784529e-01 3.10365095e-07 2.15134278e-04]\n"," [2.14592913e-10 9.99156594e-01 1.99003349e-04 6.44405722e-04]\n"," [1.63569354e-07 9.99996424e-01 6.33722692e-08 3.30149396e-06]\n"," [1.90521066e-09 9.99997258e-01 9.51561674e-08 2.60264346e-06]\n"," [1.39211540e-08 9.99995112e-01 2.27537456e-07 4.68130474e-06]\n"," [1.66505754e-10 1.00000000e+00 6.56478816e-10 2.89263511e-08]\n"," [3.48133550e-10 9.99999762e-01 8.27603674e-09 1.82978155e-07]\n"," [2.12509228e-08 9.99998927e-01 1.27218769e-09 1.11827728e-06]\n"," [4.75039656e-07 9.99620795e-01 9.84787540e-09 3.78660625e-04]\n"," [2.57749747e-07 9.99381661e-01 1.26820145e-04 4.91230923e-04]\n"," [4.66762003e-06 9.98899221e-01 8.18296103e-04 2.77854328e-04]\n"," [1.97131667e-04 9.98877585e-01 1.69505292e-04 7.55682180e-04]\n"," [2.30470550e-06 9.99996901e-01 6.16585583e-09 7.99623535e-07]\n"," [1.65790561e-06 9.99980092e-01 5.50774937e-09 1.82466774e-05]\n"," [2.67595937e-08 9.99975204e-01 1.56001545e-09 2.48104843e-05]\n"," [9.54123720e-07 9.99142170e-01 3.65228448e-06 8.53220175e-04]\n"," [2.58536943e-07 9.99554694e-01 3.84821848e-04 6.01217362e-05]\n"," [5.35725849e-05 9.91139352e-01 1.18650484e-03 7.62058888e-03]\n"," [2.03275803e-07 9.99948263e-01 3.62529545e-06 4.79218797e-05]\n"," [2.20713059e-06 9.88883078e-01 5.99789899e-03 5.11679333e-03]\n"," [2.48819947e-06 9.98098671e-01 1.40466483e-03 4.94112726e-04]\n"," [7.09752567e-05 5.20620823e-01 1.19647512e-03 4.78111684e-01]\n"," [1.51077279e-06 8.90944839e-01 4.34353249e-03 1.04710184e-01]\n"," [4.67108130e-08 9.99984264e-01 3.54100223e-07 1.53531637e-05]\n"," [2.36659758e-08 9.99986172e-01 9.37761001e-07 1.28958072e-05]\n"," [1.50989743e-09 9.99971271e-01 1.70756223e-07 2.86594895e-05]\n"," [5.32690247e-09 9.99999285e-01 1.99051073e-07 4.66936342e-07]\n"," [1.73973085e-08 9.99602139e-01 5.30052432e-07 3.97346041e-04]\n"," [3.51733327e-08 9.99971032e-01 1.28907177e-05 1.60902873e-05]\n"," [3.37695649e-10 1.00000000e+00 3.39295241e-08 5.85301017e-08]\n"," [7.21038020e-08 9.99623299e-01 4.56144917e-05 3.30957264e-04]\n"," [4.37045458e-08 9.99863148e-01 9.73830029e-05 3.94666604e-05]\n"," [5.06018296e-06 9.18860137e-01 1.83792086e-03 7.92968571e-02]\n"," [7.51045537e-09 9.99985218e-01 1.29154432e-06 1.34164893e-05]\n"," [2.96693742e-07 9.99540329e-01 1.54264751e-04 3.05146939e-04]\n"," [2.50032901e-08 9.99972105e-01 1.09289282e-07 2.78175175e-05]\n"," [1.75951365e-10 1.00000000e+00 4.00981079e-08 1.34115243e-08]\n"," [2.97729008e-10 9.99999881e-01 7.02132112e-08 5.87034990e-08]\n"," [7.22715776e-10 9.99999046e-01 5.26450492e-07 4.64661838e-07]\n"," [2.44344184e-10 9.99999166e-01 2.24941090e-07 5.90814693e-07]\n"," [3.89295846e-10 9.99999762e-01 3.02325525e-08 2.12002249e-07]\n"," [6.45283080e-08 9.99986649e-01 3.29271734e-06 9.95141727e-06]\n"," [3.96457636e-07 9.63584781e-01 1.40312705e-02 2.23835576e-02]\n"," [7.47302593e-08 9.99963045e-01 4.92730585e-08 3.68253677e-05]\n"," [5.07977802e-07 9.97264147e-01 3.00343563e-05 2.70534493e-03]\n"," [1.55416231e-08 9.99992251e-01 5.62136222e-07 7.20445541e-06]\n"," [5.93232519e-10 9.99995351e-01 1.85658553e-06 2.79139272e-06]\n"," [1.36061262e-09 9.99998212e-01 8.57124576e-07 9.10662266e-07]\n"," [2.13097415e-08 9.99995351e-01 1.84916564e-06 2.71249655e-06]\n"," [2.38237909e-08 9.99996901e-01 5.51772132e-07 2.53921212e-06]\n"," [1.22847765e-09 9.99988914e-01 2.91643012e-08 1.10632363e-05]\n"," [3.67441402e-08 9.99979377e-01 4.08022601e-07 2.02424744e-05]\n"," [3.07031889e-09 9.99997973e-01 5.62346152e-08 2.07795642e-06]\n"," [1.21065480e-09 9.99992371e-01 6.44309894e-09 7.67183974e-06]\n"," [1.04608977e-09 9.99985456e-01 3.56225200e-06 1.09990569e-05]\n"," [1.19367178e-06 9.94999886e-01 6.71891667e-06 4.99222288e-03]\n"," [2.04985810e-07 9.83194768e-01 8.15002131e-05 1.67235564e-02]\n"," [1.02571818e-09 9.99999404e-01 6.60281501e-08 4.33847248e-07]\n"," [3.36434014e-09 9.99998689e-01 1.19545717e-07 1.17386708e-06]\n"," [1.50338451e-07 9.99988556e-01 9.17157081e-07 1.04261717e-05]\n"," [5.51385256e-07 9.99991775e-01 9.86899408e-07 6.64739673e-06]\n"," [7.08598833e-08 9.99989748e-01 3.79774656e-06 6.32883211e-06]\n"," [1.32460272e-07 9.99995828e-01 1.14438694e-06 2.88478554e-06]\n"," [6.77320622e-06 9.60561752e-01 1.04805827e-06 3.94304357e-02]\n"," [9.48212232e-07 9.90823388e-01 9.21078026e-07 9.17476229e-03]\n"," [2.50694226e-04 5.98947406e-01 1.17132724e-04 4.00684774e-01]\n"," [1.82368400e-04 3.19029301e-01 1.00581747e-05 6.80778265e-01]\n"," [2.41091493e-05 9.19774652e-01 8.48082185e-04 7.93530717e-02]\n"," [2.05595961e-06 9.97401476e-01 5.34044630e-05 2.54315394e-03]\n"," [5.27636033e-08 9.99794185e-01 4.70595660e-06 2.01141273e-04]\n"," [3.60768645e-05 9.56759512e-01 1.13356556e-03 4.20708992e-02]\n"," [3.24692119e-05 9.67011154e-01 1.76732094e-04 3.27795744e-02]\n"," [1.24323208e-07 9.99589026e-01 3.15311081e-06 4.07763233e-04]\n"," [2.80750146e-06 9.99464095e-01 3.50400456e-04 1.82622825e-04]\n"," [3.43581718e-07 9.99289513e-01 2.76453618e-04 4.33621375e-04]\n"," [8.86515136e-06 8.68042588e-01 4.35816146e-05 1.31904975e-01]\n"," [1.08148038e-06 9.99455631e-01 9.11471876e-09 5.43321250e-04]\n"," [7.69701032e-08 9.89615202e-01 2.30195198e-07 1.03844041e-02]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sRkLupdy2kD_","colab_type":"code","outputId":"4ac479e5-d094-49d0-8210-7be7bc63ad7b","executionInfo":{"status":"ok","timestamp":1587169303295,"user_tz":360,"elapsed":336,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}},"colab":{"base_uri":"https://localhost:8080/","height":221}},"source":["# Convert prediction results to Pandas dataframe, for better visualization\n","import pandas as pd\n","\n","tflite_pred_dataframe = pd.DataFrame(tflite_model_predictions)\n","tflite_pred_dataframe.columns = ['bike_lane', 'crosswalk', 'sidewalk', 'street']\n","\n","print(\"TFLite prediction results for the first elements\")\n","tflite_pred_dataframe.head()"],"execution_count":7,"outputs":[{"output_type":"stream","text":["TFLite prediction results for the first elements\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>bike_lane</th>\n","      <th>crosswalk</th>\n","      <th>sidewalk</th>\n","      <th>street</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>6.615994e-09</td>\n","      <td>0.999968</td>\n","      <td>0.000004</td>\n","      <td>0.000028</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.205152e-06</td>\n","      <td>0.991672</td>\n","      <td>0.000006</td>\n","      <td>0.008321</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1.273433e-07</td>\n","      <td>0.999577</td>\n","      <td>0.000036</td>\n","      <td>0.000388</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1.109482e-06</td>\n","      <td>0.997643</td>\n","      <td>0.000094</td>\n","      <td>0.002262</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1.377098e-07</td>\n","      <td>0.999139</td>\n","      <td>0.000622</td>\n","      <td>0.000239</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      bike_lane  crosswalk  sidewalk    street\n","0  6.615994e-09   0.999968  0.000004  0.000028\n","1  1.205152e-06   0.991672  0.000006  0.008321\n","2  1.273433e-07   0.999577  0.000036  0.000388\n","3  1.109482e-06   0.997643  0.000094  0.002262\n","4  1.377098e-07   0.999139  0.000622  0.000239"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"al_kt6jXlQhB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"e951047f-e148-4be5-932a-c9dfec703913","executionInfo":{"status":"ok","timestamp":1587164489487,"user_tz":360,"elapsed":1325,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}}},"source":["# Setup to plot incorrect images\n","\n","batch_num = 0\n","BATCH_SIZE = 200\n","gen = datagen_val.flow_from_directory(\n","    data_path_eval,\n","    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n","    batch_size=BATCH_SIZE,\n","    class_mode='categorical',\n","    shuffle = False)\n","\n","def show_batch(image_batch, label_batch):\n","  plt.figure(figsize=(40,40))\n","  plt_ix = 1\n","  for n in range(len(y_pred)):\n","      if label_batch[n] != y_pred[n] and plt_ix<=36:\n","        if label_batch[n] + y_pred[n] == 3:\n","          continue \n","        ax = plt.subplot(6,6, plt_ix)\n","        plt_ix +=1\n","        plt.imshow(image_batch[n])\n","        plt.title(gen.filenames[batch_num * BATCH_SIZE + n] + '->' + CLASS_NAMES[y_pred[n]])\n","        plt.axis('off')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Found 23973 images belonging to 4 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"GvoWanBBlo0n","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"outputId":"81ab392d-1300-421b-881a-ad043235c3f9","executionInfo":{"status":"ok","timestamp":1587164500604,"user_tz":360,"elapsed":8261,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}}},"source":["# plot incorrect images from next batch\n","image_batch, label_batch = next(gen)\n","\n","label_batch = np.argmax(label_batch, axis=1)\n","Y_pred = model.predict(image_batch)\n","y_pred=np.argmax(Y_pred, axis=1)\n","\n","show_batch(image_batch, label_batch)\n","batch_num += 1\n","print(batch_num)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["1\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 2880x2880 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"0rpdkVfJlDjV","colab_type":"code","colab":{}},"source":["# download results\n","files.download(outFile)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Khz0sVmkruXi","colab_type":"code","outputId":"3308e700-736e-4628-ba67-4d853f4f3d96","executionInfo":{"status":"ok","timestamp":1586457637665,"user_tz":360,"elapsed":56651,"user":{"displayName":"Tim Everett","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiPRQ1hPu0lySQO4fY2XE-8o7JUywlvSTKiMwYUtQ=s64","userId":"01211616133197425772"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":[" # Convert to TFlite, save and download results\n","\n","model_name = 'mobileV2_LA_0407'\n","\n"," # Save model \n","model.save(model_name + '.h5')\n","model.save(saved_model_dir + model_name + '.h5')\n","tf.saved_model.save(model, model_name)\n","\n","# convert to tflite\n","converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n","tflite_model = converter.convert()\n","\n","# save TFlite model to Google drive and download folder on local drive \n","with open(saved_model_dir + model_name + '.tflite', 'wb') as f:\n","  f.write(tflite_model)\n","with open(model_name + '.tflite', 'wb') as f:\n","  f.write(tflite_model)\n","files.download(model_name + '.tflite')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n","Instructions for updating:\n","If using Keras pass *_constraint arguments to layers.\n","INFO:tensorflow:Assets written to: mobileV2_LA_0407/assets\n"],"name":"stdout"}]}]}